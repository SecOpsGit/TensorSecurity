# 使用 LSTM RNN預測Bitcoins價格
```
sudharsan13296/Hands-On-Deep-Learning-Algorithms-with-Python
https://github.com/sudharsan13296/Hands-On-Deep-Learning-Algorithms-with-Python

https://github.com/sudharsan13296/Hands-On-Deep-Learning-Algorithms-with-Python/
blob/master/05.%20Improvements%20to%20the%20RNN/5.06%20Predicting%20Bitcoins%20price%20using%20LSTM%20RNN.ipynb
```

```
!wget https://raw.githubusercontent.com/sudharsan13296/Hands-On-Deep-Learning-Algorithms-with-Python/master/05.%20Improvements%20to%20the%20RNN/data/btc.csv
```
```
# -*- coding: utf-8 -*-
"""
LSTM models are widely used for sequential datasets,  that is dataset in which order matters. 
In this section, we will learn how can we use LSTM networks for performing time series analysis. 
We will learn how to predict bitcoin prices using LSTM network.

# Import Libraries

First, we import the required libraries as follows:
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

import matplotlib.pyplot as plt
# %matplotlib inline 


import tensorflow as tf
tf.logging.set_verbosity(tf.logging.ERROR)

"""## Data Preparation 

We will see how can we prepare our dataset in a way that LSTM needs. First, we read the input dataset:
"""

df = pd.read_csv('btc.csv')

"""Display a few rows of the dataset as follows:"""

df.head()

"""As shown in the above data frame, the column Close represents the closing price of bitcoins. 
We need only the column Close to make predictions, so we take that particular column alone as follows:"""

data = df['Close'].values

"""Next, we standardize the data and bring it to the same scale,"""

scaler = StandardScaler()
data = scaler.fit_transform(data.reshape(-1, 1))

"""Plot and observe the trend of how the bitcoins price changes as follows, 
Since we scaled the price, it is not a bigger number:"""

plt.plot(data)
plt.xlabel('Days')
plt.ylabel('Price')
plt.grid()

"""We define a function called get_data which generates the input and output. 
It takes the data and window_size as an input and generates the input and target column.

What is window size? We move the x values window_size times ahead and get the y values. 
For instance, as shown in the below table with window_size = 1, Y values are just 1-time step ahead of x values.


![image to be added](images/9.png)

The get_data() function is defined as follows:
"""

def get_data(data, window_size):
    X = []
    y = []
    
    i = 0
    
    while (i + window_size) <= len(data) - 1:
        X.append(data[i:i+window_size])
        y.append(data[i+window_size])
        
        i += 1
    assert len(X) ==  len(y)
    return X, y

"""We choose window size as 7 and generate the input and output:"""

X, y = get_data(data, window_size = 7)

"""Consider the first 1000 points as a train set and the rest of the points in the dataset as the test set:"""

#train set
X_train  = np.array(X[:1000])
y_train = np.array(y[:1000])

#test set
X_test = np.array(X[1000:])
y_test = np.array(y[1000:])

"""The shape of X_train is shown as follows:"""

X_train.shape

"""What does the preceding shape mean? 
It implies that (sample_size, time_steps, features). 

LSTM requires input exactly in this format, for example:
* 1000 implies the number of data points (sample_size)
* 7 specifies the window size (time_steps) 
* 1 specifies the dimension of our dataset (features)

## Defining Network Parameters

Define the network parameters:
"""

batch_size = 7
window_size = 7 
hidden_layer = 256 
learning_rate = 0.001

"""## Defining Placeholders

Define the placeholders for our input and output:
"""

input = tf.placeholder(tf.float32, [batch_size, window_size, 1])
target = tf.placeholder(tf.float32, [batch_size, 1])

"""## Defining weights

Let's define all the weights we use in our LSTM cell.

Weights of the input gate:
"""

U_i = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))
W_i = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))
b_i = tf.Variable(tf.zeros([hidden_layer]))

"""Weights of the forget gate:"""

U_f = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))
W_f = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))
b_f = tf.Variable(tf.zeros([hidden_layer]))

"""Weights of the output gate:"""

U_o = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))
W_o = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))
b_o = tf.Variable(tf.zeros([hidden_layer]))

"""Weights of the candidate state:"""

U_g = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))
W_g = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))
b_g = tf.Variable(tf.zeros([hidden_layer]))

"""Output layer weight:"""

V = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))
b_v = tf.Variable(tf.zeros([1]))

"""## Define the LSTM cell
We define the function called LSTM_cell, 
which returns the cell state and hidden state as an output. 

Recall the steps we saw in the forward propagation of LSTM:

 $$ i_t = \sigma ( U_i x_t + W_f h_{t-1} + b_i)  $$

$$ f_t = \sigma ( U_f x_t + W_f h_{t-1} + b_f)  $$

$$  o_t = \sigma (U_o x_t + W_o h_{t-1} + b_o)  $$

$$ g_t  = tanh (U_g x_t + W_g h_{t-1} + b_g)  $$

$$ c_t = f_t  c_{t-1} + i_t {g_t}  $$

$$ h_t = o_t tanh(c_t)  $$

The LSTM cell is implemented as shown in the following code. 
It takes the input, previous hidden state, and previous cell state as inputs, 
and returns the current cell state and current hidden state.
"""

def LSTM_cell(input, prev_hidden_state, prev_cell_state):


    it = tf.sigmoid(tf.matmul(input, U_i) + tf.matmul(prev_hidden_state, W_i) + b_i)

    ft = tf.sigmoid(tf.matmul(input, U_f) + tf.matmul(prev_hidden_state, W_f) + b_f)

    ot = tf.sigmoid(tf.matmul(input, U_o) + tf.matmul(prev_hidden_state, W_o) + b_o)

    gt = tf.tanh(tf.matmul(input, U_g) + tf.matmul(prev_hidden_state, W_g) + b_g)

    ct = (prev_cell_state * ft) + (it * gt)

    ht = ot * tf.tanh(ct)

    return ct, ht

"""## Defining forward propagation

Now, we will perform forward propagation and predict the output, $\hat{y}_t$. 

$$ \hat{y}_t = Vh_t + b_v$$
"""

#initialize the list called y_hat for storing the predicted output
y_hat = []

#for each batch we compute the output and store it in the y_hat list
for i in range(batch_size): 
  
    #initialize hidden state and cell state for each batch
    hidden_state = np.zeros([1, hidden_layer], dtype=np.float32) 
    cell_state = np.zeros([1, hidden_layer], dtype=np.float32)
    
    
    #compute the hidden state and cell state of the LSTM cell for each time step
    for t in range(window_size):
        cell_state, hidden_state = LSTM_cell(tf.reshape(input[i][t], (-1, 1)), hidden_state, cell_state)
        
    #compute y_hat and append it to y_hat list
    y_hat.append(tf.matmul(hidden_state, V) + b_v)

"""## Defining backpropagation

After performing forward propagation and predicting the output, we compute the loss. We use mean squared error as our loss function and the total loss is the sum of losses across all the time steps as follows:
"""

losses = []

for i in range(len(y_hat)):
    losses.append(tf.losses.mean_squared_error(tf.reshape(target[i], (-1, 1)), y_hat[i]))
    
loss = tf.reduce_mean(losses)

"""To avoid the exploding gradient problem, we perform gradient clipping:"""

gradients = tf.gradients(loss, tf.trainable_variables())
clipped, _ = tf.clip_by_global_norm(gradients, 4.0)

"""使用 Adam optimizer 並且 minimize our loss function:"""

optimizer = tf.train.AdamOptimizer(learning_rate).apply_gradients(zip(gradients, tf.trainable_variables()))

"""## Training the LSTM model
Start the TensorFlow session and initialize all the variables:
"""

session = tf.Session()
session.run(tf.global_variables_initializer())

"""Set the number of epochs:"""

epochs = 100

for i in range(epochs):
    train_predictions = []
    index = 0
    epoch_loss = []
    
    #Sample some batche of data and train the network
    while(index + batch_size) <= len(X_train):
        
        #sample batch of data
        X_batch = X_train[index:index+batch_size]
        y_batch = y_train[index:index+batch_size]
        
        #predict the prices and compute loss
        predicted, loss_val, _ = session.run([y_hat, loss, optimizer], feed_dict={input:X_batch, target:y_batch})
        
        #store the loss
        epoch_loss.append(loss_val)
        
        #store the predictions
        train_predictions.append(predicted)
        index += batch_size
        
        
    #print the loss on every 10 iterations
    if (i % 10)== 0:
        print('Epoch {}, Loss: {} '.format(i,np.mean(epoch_loss)))

"""## Making predictions using the LSTM model

Now, we will start making predictions on the test set.
"""

predicted_output = []
i = 0
while i+batch_size <= len(X_test): 
  
    output = session.run([y_hat],feed_dict={input:X_test[i:i+batch_size]})
    i += batch_size
    predicted_output.append(output)

"""Print the predicted output"""

predicted_output[0]

"""As you can see above, the predicted values are in a nested list. So we will just flatten them."""

predicted_values_test = []
for i in range(len(predicted_output)):
  for j in range(len(predicted_output[i][0])):
    predicted_values_test.append(predicted_output[i][0][j])

"""Now if we print the predicted values, it is no longer in a nested list"""

predicted_values_test[0]

"""As we took the first 1000 points as a training set, 
we make predictions for time step greater than 1000.
"""

predictions = []
for i in range(1280):
      if i >= 1000:
        predictions.append(predicted_values_test[i-1019])
      else:
        predictions.append(None)

"""Plot and see how well the predicted value matches the actual value:"""

plt.figure(figsize=(16, 7))
plt.plot(data, label='Actual')
plt.plot(predictions, label='Predicted')
plt.legend()
plt.xlabel('Days')
plt.ylabel('Price')
plt.grid()
plt.show()

"""As you can see in the above plot, the actual value is shown in red color and the predicted value is shown in blue color. 
As we are making predictions for the time step greater than 1000, you can see after the time step 1000, 
red and blue lines interest each other, which implies that our model has correctly predicted the actual values.

In the next section, we will learn about the GRU cell which acts as a simplified version of GRU cell.
"""
```
