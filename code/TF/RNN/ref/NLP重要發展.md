#
```

可應用於實際的14個NLP突破性研究成果（一）
https://yq.aliyun.com/articles/689035
可應用於實際的14個NLP突破性研究成果（二）
https://yq.aliyun.com/articles/689082
可應用於實際的14個NLP突破性研究成果（三）
https://yq.aliyun.com/articles/689196
可應用於實際的14個NLP突破性研究成果（四）
https://kknews.cc/code/b56mazn.html

2018年，NLP研究與應用進展到什麼水平了？
2019-01-05 
https://kknews.cc/tech/2xkxx3y.html

https://kknews.cc/tech/x2ej5rq.html

```
```
Facebook這五年幹了什麼  2018-12-10 
https://kknews.cc/tech/abm9q36.html
```
### Temporal Convolutional Networks (TCN)

```
An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling
Shaojie Bai, J. Zico Kolter, Vladlen Koltun
(Submitted on 4 Mar 2018 (v1), last revised 19 Apr 2018 (this version, v2))
https://arxiv.org/abs/1803.01271
https://github.com/locuslab/TCN
```


```
摘要
對於大多數深度學習實踐者來說，序列建模(Sequence Modeling)與循環網絡(Recurrent Networks)是同義詞。
然而，最近的研究結果表明，卷積架構在語音合成和機器翻譯等任務上的表現優於循環網絡。
給定一個新的序列建模任務或數據集，應該使用哪種架構？
我們對序列建模的一般卷積和循環架構進行了系統的評價。
我們在廣泛的標準任務中評估這些模型。我們的結果表明，一個簡單的卷積架構在不同的任務和數據集上的表現優於LSTM等典型的循環網絡。
我們的結論是，需要重新考慮序列建模和循環網絡之間的共同關聯，卷積網絡應該被視為序列建模任務的一個自然起點
```


###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
###

```


```


```


```
