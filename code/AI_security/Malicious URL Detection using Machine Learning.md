# Malicious URL Detection using Machine Learning
```
https://github.com/savan77/Malicious-URL-Detection-using-Machine-Learning

```

### 其他
```
Machine Learning and Security | Using machine learning to detect malicious URLs
https://github.com/faizann24/Using-machine-learning-to-detect-malicious-URLs


Malicious-Url-Detection
Using machine learning to detect malicious urls.
https://github.com/VAD3R-95/Malicious-Url-Detection


https://vad3rblog.wordpress.com/2018/04/08/malicious-url-detection/#more-1182
```

```

# -*- coding: utf-8 -*-
"""maliciousurl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/savan77/Malicious-URL-Detection-using-Machine-Learning/blob/master/notebooks/maliciousurl.ipynb

# Import Dependencies
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
import re
import random
from sklearn.metrics import accuracy_score

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

#this function is taken from https://github.com/faizann24/Using-machine-learning-to-detect-malicious-URLs
def getTokens(input):
    tokensBySlash = str(input.encode('utf-8')).split('/')
    allTokens = []
    for i in tokensBySlash:
        tokens = str(i).split('-')
        tokensByDot = []
        for j in range(0,len(tokens)):
            tempTokens = str(tokens[j]).split('.')
            tokensByDot = tokensByDot + tempTokens
        allTokens = allTokens + tokens + tokensByDot
    allTokens = list(set(allTokens))
    if 'com' in allTokens:
        allTokens.remove('com')
    return allTokens

#function to remove "http://" from URL
def trim(url):
    return re.match(r'(?:\w*://)?(?:.*\.)?([a-zA-Z-1-9]*\.[a-zA-Z]{1,}).*', url).groups()[0]

"""# Prepare Dataset"""

#read from a file
data = pd.read_csv("../data/dataNN.csv",',',error_bad_lines=False)	#reading file
data['url'].values

len(data)







#convert it into numpy array and shuffle the dataset
data = np.array(data)
random.shuffle(data)



#convert text data into numerical data for machine learning models
y = [d[1] for d in data]
corpus = [d[0] for d in data]
vectorizer = TfidfVectorizer(tokenizer=getTokens)
X = vectorizer.fit_transform(corpus)

#split the data set inot train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Train Machine Learning Models"""

#1 - Logistic Regression
model = LogisticRegression(C=1)
model.fit(X_train, y_train)

print(model.score(X_test,y_test))

#save the model and vectorizer
joblib.dump(model, "mal-logireg1.pkl", protocol=2)
joblib.dump(vectorizer, "vectorizer1.pkl", protocol=2)

#make prediction
a = "http://www.savanvisalpara.com"
aa = vectorizer.transform([trim(a)])
s = model.predict(aa)
s[0] #0 for good

#2 - SVM
from sklearn.svm import SVC
svcModel = SVC()
svcModel.fit(X_train, y_train)
# lsvcModel = svm.LinearSVC.fit(X_train, y_train)

svcModel.score(X_test, y_test)

from sklearn.ensemble import RandomForestClassifier

m = RandomForestClassifier(n_estimators=100)
m.fit(X_train, y_train)



"""# Further experiment"""

index = int(0.3 * len(data))

from sklearn.utils import shuffle
data = pd.read_csv("data/data.csv",',',error_bad_lines=False)

data = shuffle(data)
url_train = data['url'][index:].values
label_train = data['label'][index:].values
url_test = data['url'][:index].values
label_test = data['label'][:index].values

from sklearn.pipeline import Pipeline

pipeline = Pipeline([
        ("vectorizer", TfidfVectorizer(tokenizer=getTokens)),
        ("classifier", LogisticRegression())])

pipeline.fit(url_train, label_train)

pipeline.score(url_test, label_test)

"""I have stopped working on this. You may want to use advanced methods to achieve higher accuracy(i.e LSTM). Also, a very critical part here is the feature engineering. Simlpy taking input URL as an input is not a good idea. We may find other features,which are more useful than only URL string, from host info, ip, or page content."""


```
